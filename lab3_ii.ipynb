{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторная работа 2. Обработка текста.\n",
    "\n",
    "Задание:\n",
    "\n",
    "Написать программу на языке программирования Python, реализующую:\n",
    "1)\tПредварительную обработку текста, включающую:\n",
    "\t-\tПеревод текста в нижний регистр\n",
    "\t-\tУдаление знаков препинания\n",
    "\t-\tУдаление стоп-слов\n",
    "\t-\tУдаление лишних символов\n",
    "\t-\tСтемминг и лемматизацию\n",
    "2)\tПреобразование текста в мешок слов\n",
    "3)\tПреобразование текста в N-граммы, где N=2,4\n",
    "\n",
    "Замечание!\n",
    "Желательно провести предварительную обработку текста с использованием библиотеки NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.snowball import SnowballStemmer # Стеммер для русского языка\n",
    "from nltk.stem.porter import PorterStemmer # Стеммер для английского \n",
    "from nltk.stem import WordNetLemmatizer # Лемматайзер для английского\n",
    "from nltk.corpus import wordnet\n",
    "from pymystem3 import Mystem # Лемматайзер для русского языка \n",
    "import re\n",
    "import string\n",
    "from langdetect import detect\n",
    "import logging\n",
    "import os \n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spellchecker import SpellChecker\n",
    "from num2words import num2words\n",
    "import requests\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker as EnchantChecker \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vadig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vadig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vadig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vadig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\vadig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Конфигурационный блок \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = r'D:\\Projects\\SvetlanaDmitrievna\\lab3_ii\\logs'\n",
    "os.makedirs(log_dir, exist_ok=True) \n",
    "log_filename = os.path.join(log_dir, f'{datetime.now().strftime(\"%H %M %S %Y %m %d\")} nlp.log')\n",
    "\n",
    "# Удаляем логеры, которые уже запущены по случайности \n",
    "logger = logging.getLogger()\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "    \n",
    "# Настройки для логгера \n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()  # Вывод в консоль \n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для работы с txt \n",
    "\n",
    "# Пути к файлам \n",
    "english_output_file_path = 'D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt'\n",
    "russian_output_file_path = 'D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt'\n",
    "\n",
    "def read_txt(file_path): \n",
    "\t\"\"\"\n",
    "\tСчитывает текст из файла. \n",
    "\n",
    "\t:param file_path: путь к файлу \n",
    "\t:return: содержимое файла в виде строки \n",
    "\t\"\"\"\n",
    "\n",
    "\tlogger.info(f'Reading text from file: {file_path}')\n",
    "\n",
    "\ttry: \n",
    "\t\twith open(file_path, 'r', encoding='utf-8') as file: \n",
    "\t\t\ttext = file.read()\n",
    "\n",
    "\t\tlogger.info(f'Successfully read {len(text)} chars from file.')\n",
    "\n",
    "\t\treturn text\n",
    "\t\n",
    "\texcept Exception as e: \n",
    "\t\tlogger.critical(f'Didn`t get a chance to read the text: {str(e)}')\n",
    "\t\treturn \"\"\n",
    "\t\n",
    "\t\n",
    "def text_to_txt(file_path, text, new_text=True, step='Start. To lower case.'): \n",
    "\t\"\"\"\n",
    "\tЗаписывает текст в txt. \n",
    "\n",
    "\t:param file_path: путь к файлу, куда записать текст\n",
    "\t:param text: сам обработанный текст\n",
    "\t:param new_text: Если True, то стираются прошлые данные в файле, по сути создаётся новый файл. Если False, то дополняется новым текстом. \n",
    "\t:param step: на каком этапе генерация файла. Например, 'Lemmatization' и т.д.\n",
    "\t\"\"\" \n",
    "\t\n",
    "\tif step == 'Final Preproccessed Text':\n",
    "\t\tlogger.info(f'Transmitted preprocessed text with {len(text)} chars.')\n",
    "\n",
    "\tmode = 'w' if new_text else 'a'\n",
    "\n",
    "\ttry: \n",
    "\t\twith open(file_path, mode, encoding='utf-8') as file: \n",
    "\t\t\t\n",
    "\t\t\tstart_line = f'[{step} — {datetime.now().strftime(\"%H %M %S %Y %m %d\")}]\\n\\n' if new_text else f'\\n\\n\\n[{step} — {datetime.now().strftime(\"%H %M %S %Y %m %d\")}]\\n\\n'\n",
    "\n",
    "\t\t\t# Этот блок кода сделан специально, чтобы текст можно было читать не одним\n",
    "\t\t\t# сплошным предложением\n",
    "\t\t\ttext = text.split()\n",
    "\t\t\tline = ''\n",
    "\t\t\tresult = [start_line, ]\n",
    "\t\t\tfor i, word in enumerate(text): \n",
    "\t\t\t\tif i % 15 == 0 and i != 0: \n",
    "\t\t\t\t\tline.rstrip()\n",
    "\t\t\t\t\tline += '\\n'\n",
    "\t\t\t\t\tresult.append(line)\n",
    "\t\t\t\t\tline = f'{word} '\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tline += f'{word} '\n",
    "\n",
    "\t\t\tif line: result.append(line)\n",
    "\n",
    "\t\t\tresult = ''.join(result)\n",
    "\t\t\n",
    "\t\t\tfile.write(result)\n",
    "\n",
    "\t\t\tlogger.info(f'The text for step — {step} — is written to {file_path}')\n",
    "\n",
    "\texcept Exception as e: \n",
    "\t\tlogger.critical(f'Error to write the text: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:188: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:188: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\vadig\\AppData\\Local\\Temp\\ipykernel_24108\\3550293487.py:188: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  '''\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessing: \n",
    "\t\"\"\"\n",
    "\tДелает упорядоченную предобработку текста: \n",
    "\t1. Перевод текста в нижний регистр. \n",
    "\t2. Исправление опечаток. \n",
    "\t3. Числа в строки.\n",
    "\t4. Удаление пунтуации и других символов.  \n",
    "\t5. Удаление стоп-слов. \n",
    "\t6. Нормализация текста. Лемматизация / стемминг. \n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, text, delete_punctuation_mode='string', text_normalization_method='lemma'):\n",
    "\t\t\"\"\"\n",
    "\t\tИнициализация класса TextPreprocessing.\n",
    "\n",
    "\t\t:param text: исходный текст для предобработки\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('Text is initializing...')\n",
    "\n",
    "\t\tself.text = text\n",
    "\t\tself.delete_punctuation_mode = delete_punctuation_mode\n",
    "\t\tself.language = self.__detect_language() \n",
    "\t\tself.normalization_method = text_normalization_method\n",
    "\n",
    "\t\tlogger.info(f'Text is initialized with parameters: delete_punctuation_mode={delete_punctuation_mode}, text_normalization_method={text_normalization_method}')\n",
    " \n",
    "\tdef __detect_language(self) -> str: \n",
    "\t\t\"\"\"\n",
    "\t\tАвтоматическое определение языка с помощью библиотеки langdetect. \n",
    "\n",
    "\t\t:return: Возвращается формат языка в стиле 'russian', 'english'.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tdetected_lang = detect(self.text)\n",
    "\t\t\t\n",
    "\t\t\tlang_mapping = {\n",
    "\t\t\t\t'ru': 'russian',\n",
    "\t\t\t\t'en': 'english',\n",
    "\t\t\t\t# TODO: create more languages\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tlanguage = lang_mapping[detected_lang]\n",
    "\n",
    "\t\t\tlogger.info(f'Detected language: {language}')\n",
    "\t\t\t\n",
    "\t\t\treturn language\n",
    "\t\t\n",
    "\t\texcept:\n",
    "\t\t\tlogger.critical('Error with detecting langauge.')\n",
    "\n",
    "\tdef __write_to_file(self, result_text, new_text=True, step='Start. To lower case.'): \n",
    "\t\t\"\"\"\n",
    "\t\tЗаписывает в файл текст на каком-то этапе, использую функцию text_to_txt()\n",
    "\n",
    "\t\t:param result_text: обработанный на каком-то этапе текст\n",
    "\t\t:param new_text: Если True, то стираются прошлые данные в файле, по сути создаётся новый файл. Если False, то дополняется новым текстом.\n",
    "\t\t:param step: на каком этапе генерация файла. Например, 'Lemmatization' и т.д.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tmatch self.language: \n",
    "\t\t\tcase 'russian':\n",
    "\t\t\t\ttext_to_txt(russian_output_file_path, result_text, new_text=new_text, step=step)\n",
    "\t\t\tcase 'english': \n",
    "\t\t\t\ttext_to_txt(english_output_file_path, result_text, new_text=new_text, step=step)\n",
    "\t\t\tcase _:\n",
    "\t\t\t\tlogger.warning(f'No method has been developed to allow writing to a file on {self.language}')\n",
    "\n",
    "\n",
    "\tdef __lang_to_simple_form(self) -> str: \n",
    "\t\t\"\"\"\n",
    "\t\tВовзвращает упрощенную форму языка. \n",
    "\n",
    "\t\t'english' -> 'en' \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlang_mapping = {\n",
    "\t\t\t\t'russian': 'ru', \n",
    "\t\t\t\t'english': 'en'\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\treturn lang_mapping[self.language]\n",
    " \n",
    "\tdef __to_lower_case(self) -> str:\n",
    "\t\t\"\"\"\n",
    "\t\tПриводит текст к нижнему регистру. \n",
    "\n",
    "\t\t:return: возвращаем измененный текст. \n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tlogger.info('Text has been converted to lower case.')\n",
    "\n",
    "\t\tresult_text = self.text.lower() \n",
    "\n",
    "\t\tself.__write_to_file(result_text, new_text=True, step='Start. To lower case.')\n",
    "\n",
    "\t\treturn result_text\n",
    "\t\n",
    "\tdef __correct_spell(self) -> str: \n",
    "\t\t\"\"\"\n",
    "\t\tИсправляет опечатки в тексте. \n",
    "\t\t\n",
    "\t\t:param text: исходный текст.\n",
    "    :return: текст с исправленными опечатками.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('Correction of typos initiated...')\n",
    "\n",
    "\t\ttry: \n",
    "\n",
    "\t\t\tif self.language == 'english':\n",
    "\t\t\t\tspell = SpellChecker(language=self.__lang_to_simple_form()) \n",
    "\t\t\t\twords = self.text.split() \n",
    "\t\t\t\tcorrected_words = [] \n",
    "\t\t\t\tfor word in words: \n",
    "\n",
    "\t\t\t\t\tif word.isdigit() or len(word) <= 2: \n",
    "\t\t\t\t\t\tcorrected_words.append(word)\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tcorrected_word = spell.correction(word)\n",
    "\t\t\t\t\tcorrected_words.append(corrected_word if corrected_word else word)\n",
    "\n",
    "\t\t\t\tlogger.info(f'Correction of typos initiated done with {len(corrected_words)} corrected words.')\n",
    "\t\t\t\tresult_text = ' '.join(corrected_words)\n",
    "\n",
    "\t\t\t\tself.__write_to_file(result_text, new_text=False, step='Spell correction.')\n",
    "\n",
    "\t\t\t\treturn result_text\n",
    "\t\t\t\n",
    "\t\t\t# Для русского языка используем Яндекс.Спеллер (не работает на данный момент)\n",
    "\t\t\telif self.language == 'russian':\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\turl = \"https://speller.yandex.net/services/spellservice.json/checkText\"\n",
    "\t\t\t\t\tparams = {\n",
    "\t\t\t\t\t\t\t'text': self.text,\n",
    "\t\t\t\t\t\t\t'lang': 'ru',\n",
    "\t\t\t\t\t\t\t'format': 'plain'\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tresponse = requests.get(url, params=params)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif response.status_code == 200:\n",
    "\t\t\t\t\t\t\tcorrections = response.json()\n",
    "\t\t\t\t\t\t\tresult_text = self.text\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# Применяем исправления в обратном порядке (с конца текста)\n",
    "\t\t\t\t\t\t\tfor item in reversed(corrections):\n",
    "\t\t\t\t\t\t\t\t\tpos = item['pos']\n",
    "\t\t\t\t\t\t\t\t\tlength = item['len']\n",
    "\t\t\t\t\t\t\t\t\tsuggestions = item['s']\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\tif suggestions:\n",
    "\t\t\t\t\t\t\t\t\t\t\t# Заменяем ошибочное слово на первое предложенное исправление\n",
    "\t\t\t\t\t\t\t\t\t\t\tresult_text = result_text[:pos] + suggestions[0] + result_text[pos + length:]\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tlogger.info(f'Corrected {len(corrections)} typos using Yandex.Speller')\n",
    "\n",
    "\t\t\t\t\t\t\tself.__write_to_file(result_text, new_text=False, step='Spell correction.')\n",
    "\n",
    "\t\t\t\t\t\t\treturn result_text\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tlogger.error(f'Yandex.Speller API returned status code {response.status_code}')\n",
    "\t\t\t\t\t\treturn self.text\n",
    "\n",
    "\t\texcept Exception as e: \n",
    "\t\t\tlogger.error(f'Typos correction error: {str(e)}')\n",
    "\t\t\treturn self.text\n",
    "\t\n",
    "\tdef __numbers_to_words(self) -> str: \n",
    "\t\t\"\"\"\n",
    "    Заменяет числа в тексте на их текстовые эквиваленты.\n",
    "    \n",
    "    Например:\n",
    "    - \"10 книг\" -> \"десять книг\"\n",
    "    - \"2 students\" -> \"two students\"\n",
    "    \n",
    "    :return: текст с числами, преобразованными в слова\n",
    "    \"\"\"\n",
    "\t\t\n",
    "\t\tlogger.info('Converting numbers to words...')\n",
    "\t\ttry: \n",
    "\n",
    "\t\t\tnum_lang = self.__lang_to_simple_form()\n",
    "\n",
    "\t\t\tdef replace_number(match): \n",
    "\t\t\t\t'''\n",
    "\t\t\t\tВызывается, когда находится соответствие маске '\\b\\d+[,.]?\\d*\\b'\n",
    "\n",
    "\t\t\t\t:param match: это часть текста, которая маске подошла.\n",
    "\t\t\t\t'''\n",
    "\t\t\t\ttry: \n",
    "\t\t\t\t\t# .group(0) - возвращает весь текст, а не только его какую-то группу. \n",
    "\t\t\t\t\tnumber = match.group(0)\n",
    "\n",
    "\t\t\t\t\tif '.' in number or ',' in number:\n",
    "\t\t\t\t\t\tnumber = number.replace(',', '.')\n",
    "\t\t\t\t\t\treturn num2words(float(number), lang=num_lang)\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\treturn num2words(int(number), lang=num_lang)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\texcept ValueError: \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\treturn match.group(0)\n",
    "\t\t\t\t\t\n",
    "\t\t\tresult_text = re.sub(r'\\b\\d+[,.]?\\d*\\b', replace_number, self.text)\n",
    "\n",
    "\t\t\tlogger.info('Numbers have been converted to words.')\n",
    "\n",
    "\t\t\tself.__write_to_file(result_text, new_text=False, step='Numbers to string.')\n",
    "\n",
    "\t\t\treturn result_text\n",
    "\t\t\n",
    "\t\texcept Exception as e: \n",
    "\t\t\tlogger.error(f'Error during number to word conversion: {str(e)}')\n",
    "\t\t\treturn self.text\n",
    "\n",
    "\tdef __delete_punctuation_marks(self) -> str:\n",
    "\t\t\"\"\"\n",
    "\t\tУдаляет знаки препинания из предложения.\n",
    "\n",
    "\t\tРежимы (delete_punctuation_mode): \n",
    "\t\t1. 're' — c помощью регулярных выражений. \n",
    "\t\t2. 'string' — с помощью библиотеки string.  \n",
    "\n",
    "\t\t:return: текст без знаков препинания. \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('Punctuation are being deleting...')\n",
    "\n",
    "\t\tmatch self.delete_punctuation_mode: \n",
    "\t\t\tcase 're':\n",
    "\t\t\t\tresult_text = re.sub(r'[^\\w\\s]', '', self.text)\n",
    "\t\t\t\n",
    "\t\t\tcase 'string':\n",
    "\t\t\t\t# Параметры: \n",
    "\t\t\t\t# Первый аргумент '' символы для замены \n",
    "\t\t\t\t# Второй аргумент '' символы на которые заменяем \n",
    "\t\t\t\t# Третий аргумент string.punctuation символы, которые нужно удалить \n",
    "\t\t\t\t# string.punctuation = \"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\" \n",
    "\t\t\t\ttranslator = str.maketrans('', '', ''.join(c for c in string.punctuation if c != ' '))\n",
    "\n",
    "\t\t\t\t# translate() применяет таблицу преобразования к строке \n",
    "\t\t\t\tresult_text = self.text.translate(translator)\n",
    "\t\t\t\n",
    "\t\tlogger.info('Punctuation has been deleted.')\n",
    "\n",
    "\t\tself.__write_to_file(result_text, new_text=False, step='Delete punctuation.')\n",
    "\n",
    "\t\treturn result_text \n",
    "\n",
    "\tdef __delete_stop_words(self) -> str: \n",
    "\t\t\"\"\"\n",
    "\t\tУдаляет стоп-слова. \n",
    "\n",
    "\t\tСтоп-слова — распространенные слова в языке, которые не несут значимой смысловой нагрузки \n",
    "\t\tпри анализе текста. \n",
    "\n",
    "\t\tЗачем их удалять? \n",
    "\t\t1. Текст становится меньше. \n",
    "\t\t2. Фокус на важных словах. \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('Stop words are being removed...')\n",
    "\n",
    "\t\tstopwords.words(self.language)\n",
    "\n",
    "\t\tstop_words = set(stopwords.words(self.language))\n",
    "\t\t\n",
    "\t\twords = self.text.split()\n",
    "\n",
    "\t\tfiltered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "\t\tresult_text = ' '.join(filtered_words)\n",
    "\n",
    "\t\tlogger.info('Stop words have been removed.')\n",
    "\n",
    "\t\tself.__write_to_file(result_text, new_text=False, step='Delete stop words.')\n",
    "\t\t\n",
    "\t\treturn result_text \n",
    "\t\t\n",
    "\tdef __stemming(self) -> str: \n",
    "\t\t\"\"\"\n",
    "\t\tВыполняет стемминг слов в тексте.\n",
    "\t\t\n",
    "\t\tСтемминг — процесс нахождения основы слова (стеммы) путем \n",
    "\t\tотбрасывания окончаний и суффиксов. Например, для слов \"рыбак\", \n",
    "\t\t\"рыбачить\", \"рыбный\" стеммой будет \"рыб\".\n",
    "\t\t\n",
    "\t\t:return: текст со словами, приведенными к их основам. \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('Stemming is being performed...')\n",
    "\t\t\n",
    "\t\ttry: \n",
    "\t\t\t\n",
    "\t\t\twords = self.text.split() \n",
    "\t\t\tstemmed_words = [] \n",
    "\n",
    "\t\t\tmatch self.language: \n",
    "\t\t\t\tcase 'russian': \n",
    "\t\t\t\t\tstemmer = SnowballStemmer(\"russian\")\n",
    "\t\t\t\tcase 'english': \n",
    "\t\t\t\t\tstemmer = PorterStemmer()\n",
    "\t\t\t\tcase _: \n",
    "\t\t\t\t\tlogger.error(f'Stemming not supported for language: {self.language}')\n",
    "\t\t\t\t\treturn self.text\n",
    "\n",
    "\t\t\tfor word in words:\n",
    "\t\t\t\tstemmed_words.append(stemmer.stem(word))\n",
    "\t\t\t\n",
    "\t\t\tresult_text = ' '.join(stemmed_words)\n",
    "\n",
    "\t\t\tlogger.info('Stemming has been performed.')\n",
    "\n",
    "\t\t\tself.__write_to_file(result_text, new_text=False, step='Stemming.')\n",
    "\n",
    "\t\t\treturn result_text\n",
    "\t\t\t\n",
    "\t\texcept Exception as e: \n",
    "\t\t\tlogger.error(f'Error during stemming: {str(e)}')\n",
    "\t\t\treturn self.text\n",
    "\t\t\n",
    "\tdef __lemming(self) -> str: \n",
    "\t\t\"\"\"\n",
    "\t\tВыполняет лемматизацию слов в тексте.\n",
    "\t\t\t\n",
    "\t\tЛемматизация — процесс приведения слова к его словарной форме (лемме).\n",
    "\t\tНапример, для слов \"бегущий\", \"бегает\", \"бежит\" леммой будет \"бежать\".\n",
    "\t\t\t\n",
    "\t\t:return: текст со словами в словарной форме\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('Lemmatizaion is being performed...')\n",
    "\n",
    "\t\ttry: \n",
    "\t\t\t\n",
    "\t\t\twords = self.text.split() \n",
    "\t\t\tlemmatized_words = []\n",
    "\n",
    "\t\t\tmatch self.language: \n",
    "\t\t\t\tcase 'russian': \n",
    "\t\t\t\t\t\tlemmatizer = Mystem()\n",
    "\n",
    "\t\t\t\t\t\tfor word in words: \n",
    "\t\t\t\t\t\t\ttry: \n",
    "\t\t\t\t\t\t\t\t# .parse(word) — библиотека pymorphy2 анализирует слово и \n",
    "\t\t\t\t\t\t\t\t# возвращает список всех возможных морфологических разборов этого слова.\n",
    "\t\t\t\t\t\t\t\t# мы берем [0] — наиболее вероятный\n",
    "\t\t\t\t\t\t\t\t#\n",
    "\t\t\t\t\t\t\t\t# После чего делаем нормальную форму (лемму) .normal_form\n",
    "\t\t\t\t\t\t\t\t# Для существительных - именительный падеж, единственное число\n",
    "\t\t\t\t\t\t\t\t# Для глаголов - инфинитив\n",
    "\t\t\t\t\t\t\t\t# Для прилагательных - мужской род, единственное число, именительный падеж\n",
    "\t\t\t\t\t\t\t\tlemma = ''.join(lemmatizer.lemmatize(word)).strip()\n",
    "\t\t\t\t\t\t\t\tlemmatized_words.append(lemma)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\t\t\tlogger.warning(f\"Failed to lemmatize word '{word}': {e}\")\n",
    "\t\t\t\t\t\t\t\tlemmatized_words.append(word)  # Сохраняем исходное слово\n",
    "\n",
    "\t\t\t\tcase 'english':\n",
    "\n",
    "\t\t\t\t\tlemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\t\t\t\t\t# Разобраться, что делает эта функция \n",
    "\t\t\t\t\tdef get_wordnet_pos(word):\n",
    "\t\t\t\t\t\t\"\"\"Отображает тег части речи NLTK на тег WordNet\"\"\"\n",
    "\t\t\t\t\t\ttag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "\t\t\t\t\t\ttag_dict = {\n",
    "\t\t\t\t\t\t\t\t'J': wordnet.ADJ,\n",
    "\t\t\t\t\t\t\t\t'N': wordnet.NOUN,\n",
    "\t\t\t\t\t\t\t\t'V': wordnet.VERB,\n",
    "\t\t\t\t\t\t\t\t'R': wordnet.ADV\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\treturn tag_dict.get(tag, wordnet.NOUN)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tfor word in words: \n",
    "\t\t\t\t\t\tlemma = lemmatizer.lemmatize(word, get_wordnet_pos(word))\n",
    "\t\t\t\t\t\tlemmatized_words.append(lemma)\n",
    "\n",
    "\t\t\t\tcase _: \n",
    "\t\t\t\t\tlogger.error(f'Lemmatization not supported for language: {self.language}')\n",
    "\t\t\t\t\treturn self.text\n",
    "\t\t\t\n",
    "\t\t\tresult_text = ' '.join(lemmatized_words)\n",
    "\n",
    "\t\t\tlogger.info('Lemmatization has been performed.')\n",
    "\n",
    "\t\t\tself.__write_to_file(result_text, new_text=False, step='Lemmatization.')\n",
    "\n",
    "\t\t\treturn result_text\n",
    "\t\t\t\n",
    "\t\texcept Exception as e: \n",
    "\t\t\tlogger.error(f'Error during lemmatizaion: {str(e)}')\n",
    "\t\t\treturn self.text\n",
    "\n",
    "\tdef __text_normalization(self) -> str: \n",
    "\t\t\"\"\"\n",
    "\t\tВыбирает метод нормализации текста. \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tmatch self.normalization_method: \n",
    "\t\t\tcase 'lemma': \n",
    "\t\t\t\treturn self.__lemming()\n",
    "\t\t\tcase 'stem': \n",
    "\t\t\t\treturn self.__stemming()\n",
    "\t\t\tcase _: \n",
    "\t\t\t\tlogger.warning('There is no such thing as a text normalization method')\n",
    "\t\t\t\tlogger.info('Returned text without normalization')\n",
    "\t\t\t\treturn self.text\n",
    "\n",
    "\tdef process_text(self) -> str:\n",
    "\t\t\"\"\"\n",
    "\t\tОбрабатывает текст, применяя все методы предобработки.\n",
    "\t\t\n",
    "\t\t:return: обработанный текст по всем функциям.\n",
    "\t\t\"\"\" \n",
    "\n",
    "\t\tfor func in [self.__to_lower_case, self.__correct_spell, self.__numbers_to_words, self.__delete_punctuation_marks, self.__delete_stop_words, self.__text_normalization]: \n",
    "\t\t\t\tself.text = func()\n",
    "\t\t\n",
    "\t\tlogger.info('Text preprocessing is done!')\n",
    "\n",
    "\t\treturn self.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords: \n",
    "\t\"\"\"\n",
    "\tПреобразует текст в мешок слов. \n",
    "\n",
    "\tМешок слов (Bag of Words) - это представление текста, которое описывает \n",
    "  частоту появления слов в документе. Это простая модель, игнорирующая \n",
    "  порядок слов, но сохраняющая их количество.  \n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdef __init__(self, preprocessed_text): \n",
    "\t\t\"\"\"\n",
    "\t\tИнициализация класса. \n",
    "\n",
    "\t\t:param preprocessed_text: предобработанный текст \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('BagOfWords class is initialized')\n",
    "\n",
    "\t\tif isinstance(preprocessed_text, dict):\n",
    "\t\t\t\tlogger.warning('Input is already a dictionary, not a text string')\n",
    "\t\t\t\tself.preprocessed_text = ' '.join(preprocessed_text.keys())\n",
    "\t\telse:\n",
    "\t\t\t\tself.preprocessed_text = preprocessed_text\n",
    "\t\n",
    "\tdef create_bag(self): \n",
    "\t\t\"\"\"\n",
    "    Создает мешок слов с помощью sklearn.\n",
    "    \n",
    "    :return: словарь, где ключи - слова, значения - частота их появления\n",
    "    \"\"\"\n",
    "\t\t\n",
    "\t\tlogger.info('Creating bag of words using sklearn...')\n",
    "\t\t\n",
    "\t\ttry: \n",
    "\t\t\tvectorizer = CountVectorizer()\n",
    "\n",
    "\t\t\t# fit() — обучает векторизатор \n",
    "\t\t\t# transform() — преобразует текст в числовое представление\n",
    "\t\t\t# преобразует текст в матрицу: \n",
    "\t\t\t# 1. строки соответствуют документа (в моем случае один)\n",
    "\t\t\t# 2. столбцы соответствуют уникальным словам из словаря \n",
    "\t\t\t# 3. значения в ячейках — частота появления слов в соответствующем документе \n",
    "\t\t\t#\n",
    "\t\t\t# X — объект scipy.sparse.csr_matrix (разреженная матрица)\n",
    "\t\t\t# CSR — compressed sparse row \n",
    "\t\t\t# такая матрица используется для эффективного хранения данных, где большинство элементов \n",
    "\t\t\t# равны нулю. \n",
    "\t\t\t#\n",
    "\t\t\t# Пример матрицы: \n",
    "\t\t\t# (0, 1)\t1\n",
    "\t\t\t# (0, 3)\t2\n",
    "\t\t\t# (0, 4)\t1\n",
    "\t\t\t# (0, 7)\t1\n",
    "\t\t\t# (0, 10)\t1\n",
    "\t\t\t#\n",
    "\t\t\t# (строка, столбец) сколько раз встречается \n",
    "\t\t\tX = vectorizer.fit_transform([self.preprocessed_text])\n",
    "\t\t\twords = vectorizer.get_feature_names_out()\n",
    "\n",
    "\t\t\tprint(words)\n",
    "\n",
    "\t\t\tword_freq = {} \n",
    "\t\t\tfor i, word in enumerate(words): \n",
    "\t\t\t\tcount = X.toarray()[0][i]\n",
    "\t\t\t\tif count > 0: \n",
    "\t\t\t\t\tword_freq[word] = count \n",
    "\n",
    "\t\t\tlogger.info(f'Bag of words created with {len(word_freq)} unique words using sklearn')\n",
    "\t\t\treturn word_freq \n",
    "\t\t\n",
    "\t\texcept Exception as e: \n",
    "\t\t\tlogger.info(f'Bag of words created with {len(word_freq)} unique words using sklearn')\n",
    "\t\t\treturn {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGrams: \n",
    "\t\"\"\"\n",
    "\tПреобразует текст в N-граммы - последовательности из N слов.\n",
    "\t\n",
    "\tN-грамма - это последовательность из N элементов (в данном случае, слов)\n",
    "\tидущих друг за другом в тексте.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, preprocessed_text):\n",
    "\t\t\"\"\"\n",
    "\t\tИнициализация класса.\n",
    "\t\t\n",
    "\t\t:param preprocessed_text: предобработанный текст\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info('NGrams class is initialized')\n",
    "\n",
    "\t\tself.preprocessed_text = preprocessed_text\n",
    "\n",
    "\tdef create_ngrams(self, n=2):\n",
    "\t\t\"\"\"\n",
    "\t\tСоздаёт N-граммы из предобработанного текста. \n",
    "\n",
    "\t\t:param n: размер N-граммы (количество слов в одной N-грамме)\n",
    "    :return: словарь, где ключи - N-граммы, значения - частота их появления\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tlogger.info(f'Creating {n}-grams...')\n",
    "\n",
    "\t\ttry: \n",
    "\t\t\twords = self.preprocessed_text.split() \n",
    "\n",
    "\t\t\t# Если текст короче, чем размер N-граммы, возвращаем пустой словарь\n",
    "\t\t\tif len(words) < n:\n",
    "\t\t\t\t\tlogger.warning(f'Text is too short to create {n}-grams')\n",
    "\t\t\t\t\treturn {}\n",
    "      \n",
    "\t\t\tngrams = []\n",
    "\t\t\tfor i in range(len(words) - n + 1): \n",
    "\t\t\t\tngram = ' '.join(words[i:i+n])\n",
    "\t\t\t\tngrams.append(ngram)\n",
    "\n",
    "\t\t\tngram_freq = {} \n",
    "\t\t\tfor ngram in ngrams: \n",
    "\t\t\t\tif ngram in ngram_freq: \n",
    "\t\t\t\t\tngram_freq[ngram] += 1 \n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tngram_freq[ngram] = 1 \n",
    "\t\t\t\n",
    "\t\t\tlogger.info(f'{n}-grams created with {len(ngram_freq)} unique {n}-grams')\n",
    "\t\t\treturn ngram_freq \n",
    "\t\n",
    "\t\texcept Exception as e: \n",
    "\t\t\tlogger.error(f'Error during {n}-grams creation: {str(e)}')\n",
    "\t\t\treturn {} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:53:44,094 - INFO - Reading text from file: D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/russian_text.txt\n",
      "2025-03-27 12:53:44,111 - INFO - Successfully read 2111 chars from file.\n",
      "2025-03-27 12:53:44,113 - INFO - Text is initializing...\n",
      "2025-03-27 12:53:44,132 - INFO - Detected language: russian\n",
      "2025-03-27 12:53:44,134 - INFO - Text is initialized with parameters: delete_punctuation_mode=string, text_normalization_method=stem\n",
      "2025-03-27 12:53:44,135 - INFO - Text has been converted to lower case.\n",
      "2025-03-27 12:53:44,138 - INFO - The text for step — Start. To lower case. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt\n",
      "2025-03-27 12:53:44,139 - INFO - Correction of typos initiated...\n",
      "2025-03-27 12:53:45,792 - INFO - Corrected 0 typos using Yandex.Speller\n",
      "2025-03-27 12:53:45,795 - INFO - The text for step — Spell correction. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt\n",
      "2025-03-27 12:53:45,796 - INFO - Converting numbers to words...\n",
      "2025-03-27 12:53:45,799 - INFO - Numbers have been converted to words.\n",
      "2025-03-27 12:53:45,802 - INFO - The text for step — Numbers to string. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt\n",
      "2025-03-27 12:53:45,803 - INFO - Punctuation are being deleting...\n",
      "2025-03-27 12:53:45,805 - INFO - Punctuation has been deleted.\n",
      "2025-03-27 12:53:45,808 - INFO - The text for step — Delete punctuation. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt\n",
      "2025-03-27 12:53:45,809 - INFO - Stop words are being removed...\n",
      "2025-03-27 12:53:45,812 - INFO - Stop words have been removed.\n",
      "2025-03-27 12:53:45,813 - INFO - The text for step — Delete stop words. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt\n",
      "2025-03-27 12:53:45,815 - INFO - Stemming is being performed...\n",
      "2025-03-27 12:53:45,834 - INFO - Stemming has been performed.\n",
      "2025-03-27 12:53:45,836 - INFO - The text for step — Stemming. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt\n",
      "2025-03-27 12:53:45,838 - INFO - Text preprocessing is done!\n"
     ]
    }
   ],
   "source": [
    "russian_input_file_path = 'D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/russian_text.txt'\n",
    "text = read_txt(russian_input_file_path)\n",
    "\n",
    "output = TextPreprocessing(\n",
    "\ttext, \n",
    "\tdelete_punctuation_mode='string', \n",
    "\ttext_normalization_method='stem').process_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:53:45,855 - INFO - Transmitted preprocessed text with 1524 chars.\n",
      "2025-03-27 12:53:45,858 - INFO - The text for step — Final Preproccessed Text — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_russian.txt\n"
     ]
    }
   ],
   "source": [
    "# Записываем текст в файл \n",
    "\n",
    "text_to_txt(russian_output_file_path, output, new_text=False, step='Final Preproccessed Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:53:45,874 - INFO - BagOfWords class is initialized\n",
      "2025-03-27 12:53:45,876 - INFO - Creating bag of words using sklearn...\n",
      "2025-03-27 12:53:45,883 - INFO - Bag of words created with 180 unique words using sklearn\n",
      "2025-03-27 12:53:45,884 - INFO - NGrams class is initialized\n",
      "2025-03-27 12:53:45,885 - INFO - Creating 2-grams...\n",
      "2025-03-27 12:53:45,887 - INFO - 2-grams created with 229 unique 2-grams\n",
      "2025-03-27 12:53:45,888 - INFO - NGrams class is initialized\n",
      "2025-03-27 12:53:45,890 - INFO - Creating 4-grams...\n",
      "2025-03-27 12:53:45,892 - INFO - 4-grams created with 237 unique 4-grams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['автобус' 'аренд' 'будильник' 'бутерброд' 'быстр' 'вернул' 'вечер' 'взял'\n",
      " 'взят' 'вообщ' 'восемьпятьдес' 'восемьтридца' 'врем' 'встал' 'встат'\n",
      " 'встрет' 'выключ' 'вып' 'вышел' 'гдет' 'год' 'город' 'гот' 'двадца'\n",
      " 'двасорок' 'две' 'двест' 'девян' 'девятнадцатьнол' 'девятьсорок' 'деньг'\n",
      " 'десят' 'добра' 'договор' 'дом' 'домик' 'друз' 'единиц' 'еха' 'ждал'\n",
      " 'завтр' 'заказ' 'заказа' 'законч' 'замет' 'запыха' 'зарплат' 'зуб'\n",
      " 'йогурт' 'кажд' 'каф' 'километр' 'клиент' 'коллег' 'компан' 'котор' 'коф'\n",
      " 'куп' 'кусок' 'кухн' 'лег' 'лишн' 'месяц' 'минут' 'молок' 'нажима'\n",
      " 'напитк' 'например' 'нача' 'начальник' 'нем' 'немн' 'неплох' 'нов' 'нол'\n",
      " 'нольпятнадца' 'нужн' 'обед' 'общ' 'обычн' 'одобр' 'омлет' 'опаздыва'\n",
      " 'опозда' 'оста' 'остановк' 'отлож' 'отмет' 'отчет' 'офис' 'пересла'\n",
      " 'пешк' 'письм' 'пицц' 'планирова' 'плох' 'подготов' 'пойт' 'полчас'\n",
      " 'поровн' 'последн' 'посмотрет' 'потрат' 'почемут' 'почист' 'почт' 'правд'\n",
      " 'предлож' 'предостав' 'приготов' 'придет' 'примерн' 'принес' 'пришел'\n",
      " 'пришл' 'провер' 'проснул' 'пят' 'пятнадца' 'пятьдес' 'работ' 'работа'\n",
      " 'разговарива' 'расстоян' 'расход' 'результат' 'реклам' 'реш' 'рубл'\n",
      " 'сделк' 'сегодн' 'семьнол' 'семьпятнадца' 'середин' 'сказа' 'скидк'\n",
      " 'снов' 'снят' 'собира' 'собра' 'соглас' 'сок' 'сообщ' 'сорок' 'состав'\n",
      " 'сотрудник' 'спат' 'сплю' 'срочн' 'стака' 'сто' 'стоя' 'сумм' 'сутк'\n",
      " 'съел' 'сыр' 'сюрприз' 'телевизор' 'товар' 'тридца' 'тринадцатьпятнадца'\n",
      " 'тысяч' 'увидел' 'указа' 'ум' 'уснул' 'успет' 'установл' 'ушл' 'фильм'\n",
      " 'холодильник' 'хот' 'цел' 'час' 'чашк' 'человек' 'шел' 'шестьсорок' 'эт'\n",
      " 'яйц']\n",
      "{'автобус': 2, 'аренд': 1, 'будильник': 1, 'бутерброд': 2, 'быстр': 1, 'вернул': 1, 'вечер': 1, 'взял': 1, 'взят': 1, 'вообщ': 1, 'восемьпятьдес': 1, 'восемьтридца': 1, 'врем': 1, 'встал': 1, 'встат': 1, 'встрет': 2, 'выключ': 1, 'вып': 1, 'вышел': 1, 'гдет': 1, 'год': 1, 'город': 1, 'гот': 1, 'двадца': 5, 'двасорок': 1, 'две': 1, 'двест': 3, 'девян': 1, 'девятнадцатьнол': 1, 'девятьсорок': 1, 'деньг': 1, 'десят': 1, 'добра': 1, 'договор': 1, 'дом': 2, 'домик': 1, 'друз': 2, 'единиц': 1, 'еха': 1, 'ждал': 1, 'завтр': 1, 'заказ': 1, 'заказа': 1, 'законч': 1, 'замет': 1, 'запыха': 1, 'зарплат': 1, 'зуб': 1, 'йогурт': 1, 'кажд': 1, 'каф': 1, 'километр': 1, 'клиент': 1, 'коллег': 1, 'компан': 1, 'котор': 2, 'коф': 1, 'куп': 1, 'кусок': 1, 'кухн': 1, 'лег': 1, 'лишн': 1, 'месяц': 1, 'минут': 4, 'молок': 1, 'нажима': 1, 'напитк': 1, 'например': 1, 'нача': 1, 'начальник': 2, 'нем': 1, 'немн': 1, 'неплох': 1, 'нов': 1, 'нол': 5, 'нольпятнадца': 1, 'нужн': 3, 'обед': 1, 'общ': 1, 'обычн': 1, 'одобр': 1, 'омлет': 1, 'опаздыва': 2, 'опозда': 1, 'оста': 1, 'остановк': 1, 'отлож': 1, 'отмет': 1, 'отчет': 2, 'офис': 2, 'пересла': 1, 'пешк': 1, 'письм': 2, 'пицц': 2, 'планирова': 1, 'плох': 1, 'подготов': 1, 'пойт': 1, 'полчас': 1, 'поровн': 1, 'последн': 1, 'посмотрет': 1, 'потрат': 1, 'почемут': 2, 'почист': 1, 'почт': 1, 'правд': 1, 'предлож': 1, 'предостав': 1, 'приготов': 1, 'придет': 1, 'примерн': 1, 'принес': 1, 'пришел': 1, 'пришл': 1, 'провер': 1, 'проснул': 2, 'пят': 10, 'пятнадца': 3, 'пятьдес': 1, 'работ': 3, 'работа': 1, 'разговарива': 1, 'расстоян': 1, 'расход': 1, 'результат': 1, 'реклам': 1, 'реш': 3, 'рубл': 9, 'сделк': 1, 'сегодн': 2, 'семьнол': 1, 'семьпятнадца': 1, 'середин': 1, 'сказа': 1, 'скидк': 1, 'снов': 1, 'снят': 1, 'собира': 1, 'собра': 1, 'соглас': 1, 'сок': 1, 'сообщ': 1, 'сорок': 1, 'состав': 1, 'сотрудник': 1, 'спат': 1, 'сплю': 1, 'срочн': 1, 'стака': 1, 'сто': 2, 'стоя': 1, 'сумм': 1, 'сутк': 1, 'съел': 1, 'сыр': 1, 'сюрприз': 1, 'телевизор': 1, 'товар': 1, 'тридца': 3, 'тринадцатьпятнадца': 1, 'тысяч': 1, 'увидел': 1, 'указа': 1, 'ум': 1, 'уснул': 1, 'успет': 1, 'установл': 1, 'ушл': 1, 'фильм': 1, 'холодильник': 1, 'хот': 1, 'цел': 1, 'час': 1, 'чашк': 1, 'человек': 1, 'шел': 2, 'шестьсорок': 1, 'эт': 2, 'яйц': 1}\n",
      "{'сегодн проснул': 1, 'проснул семьпятнадца': 1, 'семьпятнадца хот': 1, 'хот будильник': 1, 'будильник установл': 1, 'установл шестьсорок': 1, 'шестьсорок пят': 1, 'пят почемут': 1, 'почемут нажима': 1, 'нажима отлож': 1, 'отлож сплю': 1, 'сплю лишн': 1, 'лишн полчас': 1, 'полчас встал': 1, 'встал ум': 1, 'ум почист': 1, 'почист зуб': 1, 'зуб —': 1, '— обычн': 1, 'обычн кухн': 1, 'кухн замет': 1, 'замет холодильник': 1, 'холодильник оста': 1, 'оста яйц': 1, 'яйц молок': 1, 'молок вообщ': 1, 'вообщ эт': 1, 'эт плох': 1, 'плох планирова': 1, 'планирова приготов': 1, 'приготов омлет': 1, 'омлет пришл': 1, 'пришл взят': 1, 'взят йогурт': 1, 'йогурт тридца': 1, 'тридца рубл': 1, 'рубл бутерброд': 1, 'бутерброд сыр': 1, 'сыр восемьтридца': 1, 'восемьтридца вышел': 1, 'вышел дом': 1, 'дом успет': 1, 'успет автобус': 1, 'автобус работ': 1, 'работ еха': 1, 'еха примерн': 1, 'примерн двадца': 1, 'двадца пят': 2, 'пят минут': 3, 'минут сегодн': 1, 'сегодн автобус': 1, 'автобус почемут': 1, 'почемут опаздыва': 1, 'опаздыва стоя': 1, 'стоя остановк': 1, 'остановк восемьпятьдес': 1, 'восемьпятьдес реш': 1, 'реш пойт': 1, 'пойт пешк': 1, 'пешк расстоян': 1, 'расстоян офис': 1, 'офис две': 1, 'две цел': 1, 'цел пят': 1, 'пят десят': 1, 'десят километр': 1, 'километр добра': 1, 'добра тридца': 1, 'тридца пят': 1, 'минут правд': 1, 'правд немн': 1, 'немн запыха': 1, 'запыха шел': 1, 'шел быстр': 1, 'быстр работ': 1, 'работ ждал': 1, 'ждал сюрприз': 1, 'сюрприз начальник': 1, 'начальник сказа': 1, 'сказа нужн': 1, 'нужн срочн': 1, 'срочн подготов': 1, 'подготов отчет': 1, 'отчет последн': 1, 'последн месяц': 1, 'месяц нем': 1, 'нем нужн': 1, 'нужн указа': 1, 'указа расход': 1, 'расход компан': 1, 'компан например': 1, 'например реклам': 1, 'реклам потрат': 1, 'потрат сто': 1, 'сто двадца': 2, 'пят нол': 2, 'нол рубл': 5, 'рубл аренд': 1, 'аренд офис': 1, 'офис —': 1, '— девян': 1, 'девян пят': 1, 'рубл зарплат': 1, 'зарплат сотрудник': 1, 'сотрудник ушл': 1, 'ушл двест': 1, 'двест нол': 1, 'рубл нача': 1, 'нача работа': 1, 'работа отчет': 1, 'отчет девятьсорок': 1, 'девятьсорок пят': 1, 'пят законч': 1, 'законч тринадцатьпятнадца': 1, 'тринадцатьпятнадца эт': 1, 'эт врем': 1, 'врем вып': 1, 'вып чашк': 1, 'чашк коф': 1, 'коф съел': 1, 'съел бутерброд': 1, 'бутерброд котор': 1, 'котор принес': 1, 'принес коллег': 1, 'коллег обед': 1, 'обед провер': 1, 'провер почт': 1, 'почт увидел': 1, 'увидел письм': 1, 'письм клиент': 1, 'клиент сообщ': 1, 'сообщ гот': 1, 'гот куп': 1, 'куп пятьдес': 1, 'пятьдес единиц': 1, 'единиц товар': 1, 'товар предостав': 1, 'предостав скидк': 1, 'скидк пятнадца': 1, 'пятнадца пересла': 1, 'пересла письм': 1, 'письм начальник': 1, 'начальник одобр': 1, 'одобр сделк': 1, 'сделк общ': 1, 'общ сумм': 1, 'сумм заказ': 1, 'заказ состав': 1, 'состав двест': 1, 'двест тридца': 1, 'тридца нол': 1, 'рубл неплох': 1, 'неплох результат': 1, 'результат вечер': 1, 'вечер встрет': 1, 'встрет друз': 1, 'друз каф': 1, 'каф договор': 1, 'договор встрет': 1, 'встрет девятнадцатьнол': 1, 'девятнадцатьнол опозда': 1, 'опозда пятнадца': 1, 'пятнадца минут': 1, 'минут пришел': 1, 'пришел заказа': 1, 'заказа пицц': 1, 'пицц напитк': 1, 'напитк взял': 1, 'взял кусок': 1, 'кусок пицц': 1, 'пицц двест': 1, 'двест двадца': 1, 'двадца рубл': 2, 'рубл стака': 1, 'стака сок': 1, 'сок сто': 1, 'рубл разговарива': 1, 'разговарива собира': 1, 'собира отмет': 1, 'отмет нов': 1, 'нов год': 1, 'год друз': 1, 'друз предлож': 1, 'предлож снят': 1, 'снят домик': 1, 'домик город': 1, 'город пятнадца': 1, 'пятнадца нол': 1, 'рубл сутк': 1, 'сутк соглас': 1, 'соглас реш': 1, 'реш собра': 1, 'собра деньг': 1, 'деньг поровн': 1, 'поровн кажд': 1, 'кажд придет': 1, 'придет тысяч': 1, 'тысяч рубл': 1, 'рубл пят': 1, 'пят человек': 1, 'человек вернул': 1, 'вернул дом': 1, 'дом двадца': 1, 'двадца двасорок': 1, 'двасорок пят': 1, 'пят реш': 1, 'реш посмотрет': 1, 'посмотрет фильм': 1, 'фильм котор': 1, 'котор шел': 1, 'шел час': 1, 'час сорок': 1, 'сорок пят': 1, 'минут уснул': 1, 'уснул гдет': 1, 'гдет середин': 1, 'середин проснул': 1, 'проснул нольпятнадца': 1, 'нольпятнадца выключ': 1, 'выключ телевизор': 1, 'телевизор лег': 1, 'лег спат': 1, 'спат завтр': 1, 'завтр снов': 1, 'снов работ': 1, 'работ нужн': 1, 'нужн встат': 1, 'встат семьнол': 1, 'семьнол опаздыва': 1}\n",
      "{'сегодн проснул семьпятнадца хот': 1, 'проснул семьпятнадца хот будильник': 1, 'семьпятнадца хот будильник установл': 1, 'хот будильник установл шестьсорок': 1, 'будильник установл шестьсорок пят': 1, 'установл шестьсорок пят почемут': 1, 'шестьсорок пят почемут нажима': 1, 'пят почемут нажима отлож': 1, 'почемут нажима отлож сплю': 1, 'нажима отлож сплю лишн': 1, 'отлож сплю лишн полчас': 1, 'сплю лишн полчас встал': 1, 'лишн полчас встал ум': 1, 'полчас встал ум почист': 1, 'встал ум почист зуб': 1, 'ум почист зуб —': 1, 'почист зуб — обычн': 1, 'зуб — обычн кухн': 1, '— обычн кухн замет': 1, 'обычн кухн замет холодильник': 1, 'кухн замет холодильник оста': 1, 'замет холодильник оста яйц': 1, 'холодильник оста яйц молок': 1, 'оста яйц молок вообщ': 1, 'яйц молок вообщ эт': 1, 'молок вообщ эт плох': 1, 'вообщ эт плох планирова': 1, 'эт плох планирова приготов': 1, 'плох планирова приготов омлет': 1, 'планирова приготов омлет пришл': 1, 'приготов омлет пришл взят': 1, 'омлет пришл взят йогурт': 1, 'пришл взят йогурт тридца': 1, 'взят йогурт тридца рубл': 1, 'йогурт тридца рубл бутерброд': 1, 'тридца рубл бутерброд сыр': 1, 'рубл бутерброд сыр восемьтридца': 1, 'бутерброд сыр восемьтридца вышел': 1, 'сыр восемьтридца вышел дом': 1, 'восемьтридца вышел дом успет': 1, 'вышел дом успет автобус': 1, 'дом успет автобус работ': 1, 'успет автобус работ еха': 1, 'автобус работ еха примерн': 1, 'работ еха примерн двадца': 1, 'еха примерн двадца пят': 1, 'примерн двадца пят минут': 1, 'двадца пят минут сегодн': 1, 'пят минут сегодн автобус': 1, 'минут сегодн автобус почемут': 1, 'сегодн автобус почемут опаздыва': 1, 'автобус почемут опаздыва стоя': 1, 'почемут опаздыва стоя остановк': 1, 'опаздыва стоя остановк восемьпятьдес': 1, 'стоя остановк восемьпятьдес реш': 1, 'остановк восемьпятьдес реш пойт': 1, 'восемьпятьдес реш пойт пешк': 1, 'реш пойт пешк расстоян': 1, 'пойт пешк расстоян офис': 1, 'пешк расстоян офис две': 1, 'расстоян офис две цел': 1, 'офис две цел пят': 1, 'две цел пят десят': 1, 'цел пят десят километр': 1, 'пят десят километр добра': 1, 'десят километр добра тридца': 1, 'километр добра тридца пят': 1, 'добра тридца пят минут': 1, 'тридца пят минут правд': 1, 'пят минут правд немн': 1, 'минут правд немн запыха': 1, 'правд немн запыха шел': 1, 'немн запыха шел быстр': 1, 'запыха шел быстр работ': 1, 'шел быстр работ ждал': 1, 'быстр работ ждал сюрприз': 1, 'работ ждал сюрприз начальник': 1, 'ждал сюрприз начальник сказа': 1, 'сюрприз начальник сказа нужн': 1, 'начальник сказа нужн срочн': 1, 'сказа нужн срочн подготов': 1, 'нужн срочн подготов отчет': 1, 'срочн подготов отчет последн': 1, 'подготов отчет последн месяц': 1, 'отчет последн месяц нем': 1, 'последн месяц нем нужн': 1, 'месяц нем нужн указа': 1, 'нем нужн указа расход': 1, 'нужн указа расход компан': 1, 'указа расход компан например': 1, 'расход компан например реклам': 1, 'компан например реклам потрат': 1, 'например реклам потрат сто': 1, 'реклам потрат сто двадца': 1, 'потрат сто двадца пят': 1, 'сто двадца пят нол': 1, 'двадца пят нол рубл': 1, 'пят нол рубл аренд': 1, 'нол рубл аренд офис': 1, 'рубл аренд офис —': 1, 'аренд офис — девян': 1, 'офис — девян пят': 1, '— девян пят нол': 1, 'девян пят нол рубл': 1, 'пят нол рубл зарплат': 1, 'нол рубл зарплат сотрудник': 1, 'рубл зарплат сотрудник ушл': 1, 'зарплат сотрудник ушл двест': 1, 'сотрудник ушл двест нол': 1, 'ушл двест нол рубл': 1, 'двест нол рубл нача': 1, 'нол рубл нача работа': 1, 'рубл нача работа отчет': 1, 'нача работа отчет девятьсорок': 1, 'работа отчет девятьсорок пят': 1, 'отчет девятьсорок пят законч': 1, 'девятьсорок пят законч тринадцатьпятнадца': 1, 'пят законч тринадцатьпятнадца эт': 1, 'законч тринадцатьпятнадца эт врем': 1, 'тринадцатьпятнадца эт врем вып': 1, 'эт врем вып чашк': 1, 'врем вып чашк коф': 1, 'вып чашк коф съел': 1, 'чашк коф съел бутерброд': 1, 'коф съел бутерброд котор': 1, 'съел бутерброд котор принес': 1, 'бутерброд котор принес коллег': 1, 'котор принес коллег обед': 1, 'принес коллег обед провер': 1, 'коллег обед провер почт': 1, 'обед провер почт увидел': 1, 'провер почт увидел письм': 1, 'почт увидел письм клиент': 1, 'увидел письм клиент сообщ': 1, 'письм клиент сообщ гот': 1, 'клиент сообщ гот куп': 1, 'сообщ гот куп пятьдес': 1, 'гот куп пятьдес единиц': 1, 'куп пятьдес единиц товар': 1, 'пятьдес единиц товар предостав': 1, 'единиц товар предостав скидк': 1, 'товар предостав скидк пятнадца': 1, 'предостав скидк пятнадца пересла': 1, 'скидк пятнадца пересла письм': 1, 'пятнадца пересла письм начальник': 1, 'пересла письм начальник одобр': 1, 'письм начальник одобр сделк': 1, 'начальник одобр сделк общ': 1, 'одобр сделк общ сумм': 1, 'сделк общ сумм заказ': 1, 'общ сумм заказ состав': 1, 'сумм заказ состав двест': 1, 'заказ состав двест тридца': 1, 'состав двест тридца нол': 1, 'двест тридца нол рубл': 1, 'тридца нол рубл неплох': 1, 'нол рубл неплох результат': 1, 'рубл неплох результат вечер': 1, 'неплох результат вечер встрет': 1, 'результат вечер встрет друз': 1, 'вечер встрет друз каф': 1, 'встрет друз каф договор': 1, 'друз каф договор встрет': 1, 'каф договор встрет девятнадцатьнол': 1, 'договор встрет девятнадцатьнол опозда': 1, 'встрет девятнадцатьнол опозда пятнадца': 1, 'девятнадцатьнол опозда пятнадца минут': 1, 'опозда пятнадца минут пришел': 1, 'пятнадца минут пришел заказа': 1, 'минут пришел заказа пицц': 1, 'пришел заказа пицц напитк': 1, 'заказа пицц напитк взял': 1, 'пицц напитк взял кусок': 1, 'напитк взял кусок пицц': 1, 'взял кусок пицц двест': 1, 'кусок пицц двест двадца': 1, 'пицц двест двадца рубл': 1, 'двест двадца рубл стака': 1, 'двадца рубл стака сок': 1, 'рубл стака сок сто': 1, 'стака сок сто двадца': 1, 'сок сто двадца рубл': 1, 'сто двадца рубл разговарива': 1, 'двадца рубл разговарива собира': 1, 'рубл разговарива собира отмет': 1, 'разговарива собира отмет нов': 1, 'собира отмет нов год': 1, 'отмет нов год друз': 1, 'нов год друз предлож': 1, 'год друз предлож снят': 1, 'друз предлож снят домик': 1, 'предлож снят домик город': 1, 'снят домик город пятнадца': 1, 'домик город пятнадца нол': 1, 'город пятнадца нол рубл': 1, 'пятнадца нол рубл сутк': 1, 'нол рубл сутк соглас': 1, 'рубл сутк соглас реш': 1, 'сутк соглас реш собра': 1, 'соглас реш собра деньг': 1, 'реш собра деньг поровн': 1, 'собра деньг поровн кажд': 1, 'деньг поровн кажд придет': 1, 'поровн кажд придет тысяч': 1, 'кажд придет тысяч рубл': 1, 'придет тысяч рубл пят': 1, 'тысяч рубл пят человек': 1, 'рубл пят человек вернул': 1, 'пят человек вернул дом': 1, 'человек вернул дом двадца': 1, 'вернул дом двадца двасорок': 1, 'дом двадца двасорок пят': 1, 'двадца двасорок пят реш': 1, 'двасорок пят реш посмотрет': 1, 'пят реш посмотрет фильм': 1, 'реш посмотрет фильм котор': 1, 'посмотрет фильм котор шел': 1, 'фильм котор шел час': 1, 'котор шел час сорок': 1, 'шел час сорок пят': 1, 'час сорок пят минут': 1, 'сорок пят минут уснул': 1, 'пят минут уснул гдет': 1, 'минут уснул гдет середин': 1, 'уснул гдет середин проснул': 1, 'гдет середин проснул нольпятнадца': 1, 'середин проснул нольпятнадца выключ': 1, 'проснул нольпятнадца выключ телевизор': 1, 'нольпятнадца выключ телевизор лег': 1, 'выключ телевизор лег спат': 1, 'телевизор лег спат завтр': 1, 'лег спат завтр снов': 1, 'спат завтр снов работ': 1, 'завтр снов работ нужн': 1, 'снов работ нужн встат': 1, 'работ нужн встат семьнол': 1, 'нужн встат семьнол опаздыва': 1}\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = BagOfWords(output).create_bag()\n",
    "bigrams = NGrams(output).create_ngrams(n=2)\n",
    "ngrams = NGrams(output).create_ngrams(n=4)\n",
    "\n",
    "\n",
    "print(bag_of_words)\n",
    "print(bigrams)\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:53:45,909 - INFO - Reading text from file: D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/english_text.txt\n",
      "2025-03-27 12:53:45,912 - INFO - Successfully read 2217 chars from file.\n",
      "2025-03-27 12:53:45,913 - INFO - Text is initializing...\n",
      "2025-03-27 12:53:45,928 - INFO - Detected language: english\n",
      "2025-03-27 12:53:45,929 - INFO - Text is initialized with parameters: delete_punctuation_mode=string, text_normalization_method=lemma\n",
      "2025-03-27 12:53:45,931 - INFO - Text has been converted to lower case.\n",
      "2025-03-27 12:53:45,933 - INFO - The text for step — Start. To lower case. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt\n",
      "2025-03-27 12:53:45,934 - INFO - Correction of typos initiated...\n",
      "2025-03-27 12:53:55,792 - INFO - Correction of typos initiated done with 441 corrected words.\n",
      "2025-03-27 12:53:55,794 - INFO - The text for step — Spell correction. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt\n",
      "2025-03-27 12:53:55,803 - INFO - Converting numbers to words...\n",
      "2025-03-27 12:53:55,805 - INFO - Numbers have been converted to words.\n",
      "2025-03-27 12:53:55,808 - INFO - The text for step — Numbers to string. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt\n",
      "2025-03-27 12:53:55,809 - INFO - Punctuation are being deleting...\n",
      "2025-03-27 12:53:55,810 - INFO - Punctuation has been deleted.\n",
      "2025-03-27 12:53:55,812 - INFO - The text for step — Delete punctuation. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt\n",
      "2025-03-27 12:53:55,814 - INFO - Stop words are being removed...\n",
      "2025-03-27 12:53:55,817 - INFO - Stop words have been removed.\n",
      "2025-03-27 12:53:55,820 - INFO - The text for step — Delete stop words. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt\n",
      "2025-03-27 12:53:55,823 - INFO - Lemmatizaion is being performed...\n",
      "2025-03-27 12:53:55,847 - INFO - Lemmatization has been performed.\n",
      "2025-03-27 12:53:55,848 - INFO - The text for step — Lemmatization. — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt\n",
      "2025-03-27 12:53:55,850 - INFO - Text preprocessing is done!\n"
     ]
    }
   ],
   "source": [
    "english_input_file_path = 'D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/english_text.txt'\n",
    "text = read_txt(english_input_file_path)\n",
    "\n",
    "eng_output = TextPreprocessing(\n",
    "\ttext, \n",
    "\ttext_normalization_method='lemma', \n",
    "\tdelete_punctuation_mode='string').process_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:53:55,863 - INFO - Transmitted preprocessed text with 1408 chars.\n",
      "2025-03-27 12:53:55,866 - INFO - The text for step — Final Preproccessed Text — is written to D:/Projects/SvetlanaDmitrievna/lab3_ii/texts/output_english.txt\n"
     ]
    }
   ],
   "source": [
    "# Записываем текст в файл \n",
    "\n",
    "text_to_txt(english_output_file_path, eng_output, new_text=False, step='Final Preproccessed Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 12:53:55,891 - INFO - BagOfWords class is initialized\n",
      "2025-03-27 12:53:55,892 - INFO - Creating bag of words using sklearn...\n",
      "2025-03-27 12:53:55,898 - INFO - Bag of words created with 174 unique words using sklearn\n",
      "2025-03-27 12:53:55,899 - INFO - NGrams class is initialized\n",
      "2025-03-27 12:53:55,900 - INFO - Creating 2-grams...\n",
      "2025-03-27 12:53:55,902 - INFO - 2-grams created with 230 unique 2-grams\n",
      "2025-03-27 12:53:55,903 - INFO - NGrams class is initialized\n",
      "2025-03-27 12:53:55,905 - INFO - Creating 4-grams...\n",
      "2025-03-27 12:53:55,906 - INFO - 4-grams created with 231 unique 4-grams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accidentally' 'add' 'alarm' 'almost' 'arent' 'article' 'ask' 'asleep'\n",
      " 'bad' 'battery' 'bed' 'bit' 'bos' 'bread' 'browsing' 'burn' 'buy' 'cant'\n",
      " 'cash' 'cashier' 'cent' 'central' 'change' 'charger' 'checkout' 'chicken'\n",
      " 'come' 'computer' 'cook' 'cooky' 'couldnt' 'date' 'day' 'decide' 'dinner'\n",
      " 'disappear' 'dont' 'early' 'eighteen' 'eightthirty' 'elevenfortyfive'\n",
      " 'end' 'enough' 'episode' 'everything' 'expiration' 'fall' 'fast'\n",
      " 'favorite' 'fifteen' 'file' 'finally' 'five' 'forget' 'forgot'\n",
      " 'forgotten' 'forty' 'found' 'four' 'fridge' 'friend' 'gallon' 'get' 'go'\n",
      " 'good' 'hadnt' 'head' 'heat' 'help' 'hmm' 'home' 'hope' 'ill' 'inflation'\n",
      " 'instead' 'keep' 'kept' 'later' 'liberty' 'like' 'loaf' 'long' 'maybe'\n",
      " 'medium' 'meet' 'meeting' 'might' 'mike' 'milk' 'minute' 'much' 'need'\n",
      " 'next' 'nine' 'oh' 'oil' 'old' 'onion' 'open' 'overall' 'oversleep'\n",
      " 'pack' 'pan' 'park' 'phone' 'picked' 'pm' 'point' 'potato' 'pour' 'price'\n",
      " 'probably' 'ran' 'reach' 'read' 'ready' 'realize' 'regret' 'relax'\n",
      " 'report' 'risk' 'salty' 'sat' 'save' 'saw' 'say' 'scar' 'set' 'seven'\n",
      " 'show' 'sit' 'six' 'sixfortyfive' 'sizzle' 'social' 'something' 'start'\n",
      " 'store' 'suppose' 'tag' 'take' 'taste' 'ten' 'text' 'thing' 'think'\n",
      " 'thirty' 'thirtythree' 'thought' 'three' 'threezero' 'tire' 'today'\n",
      " 'tomorrow' 'total' 'twelvefifteen' 'twelvethirteen' 'twenty' 'two' 'use'\n",
      " 'wage' 'wake' 'wallet' 'want' 'waste' 'watch' 'way' 'work' 'wouldve'\n",
      " 'write' 'wrong' 'year' 'yes' 'yesterday']\n",
      "{'accidentally': 1, 'add': 1, 'alarm': 1, 'almost': 1, 'arent': 1, 'article': 1, 'ask': 3, 'asleep': 1, 'bad': 1, 'battery': 1, 'bed': 2, 'bit': 1, 'bos': 1, 'bread': 2, 'browsing': 1, 'burn': 1, 'buy': 1, 'cant': 1, 'cash': 1, 'cashier': 1, 'cent': 1, 'central': 1, 'change': 1, 'charger': 1, 'checkout': 1, 'chicken': 2, 'come': 1, 'computer': 1, 'cook': 2, 'cooky': 1, 'couldnt': 1, 'date': 1, 'day': 2, 'decide': 1, 'dinner': 3, 'disappear': 1, 'dont': 2, 'early': 1, 'eighteen': 1, 'eightthirty': 1, 'elevenfortyfive': 1, 'end': 1, 'enough': 1, 'episode': 1, 'everything': 1, 'expiration': 1, 'fall': 1, 'fast': 1, 'favorite': 1, 'fifteen': 1, 'file': 1, 'finally': 1, 'five': 2, 'forget': 1, 'forgot': 1, 'forgotten': 1, 'forty': 1, 'found': 1, 'four': 2, 'fridge': 1, 'friend': 1, 'gallon': 1, 'get': 2, 'go': 4, 'good': 1, 'hadnt': 1, 'head': 1, 'heat': 1, 'help': 1, 'hmm': 1, 'home': 3, 'hope': 1, 'ill': 1, 'inflation': 1, 'instead': 1, 'keep': 1, 'kept': 1, 'later': 1, 'liberty': 1, 'like': 1, 'loaf': 1, 'long': 1, 'maybe': 1, 'medium': 1, 'meet': 1, 'meeting': 1, 'might': 1, 'mike': 2, 'milk': 2, 'minute': 3, 'much': 1, 'need': 3, 'next': 1, 'nine': 4, 'oh': 1, 'oil': 1, 'old': 1, 'onion': 1, 'open': 1, 'overall': 1, 'oversleep': 1, 'pack': 1, 'pan': 1, 'park': 5, 'phone': 1, 'picked': 1, 'pm': 2, 'point': 5, 'potato': 1, 'pour': 2, 'price': 1, 'probably': 1, 'ran': 1, 'reach': 1, 'read': 1, 'ready': 1, 'realize': 2, 'regret': 1, 'relax': 1, 'report': 2, 'risk': 1, 'salty': 1, 'sat': 1, 'save': 1, 'saw': 1, 'say': 5, 'scar': 1, 'set': 1, 'seven': 3, 'show': 1, 'sit': 1, 'six': 1, 'sixfortyfive': 1, 'sizzle': 1, 'social': 1, 'something': 1, 'start': 4, 'store': 1, 'suppose': 2, 'tag': 1, 'take': 1, 'taste': 1, 'ten': 1, 'text': 1, 'thing': 1, 'think': 1, 'thirty': 1, 'thirtythree': 1, 'thought': 2, 'three': 2, 'threezero': 1, 'tire': 1, 'today': 1, 'tomorrow': 2, 'total': 1, 'twelvefifteen': 1, 'twelvethirteen': 1, 'twenty': 1, 'two': 2, 'use': 1, 'wage': 1, 'wake': 1, 'wallet': 1, 'want': 1, 'waste': 1, 'watch': 1, 'way': 1, 'work': 2, 'wouldve': 1, 'write': 2, 'wrong': 1, 'year': 1, 'yes': 1, 'yesterday': 1}\n",
      "{'yesterday go': 1, 'go store': 1, 'store buy': 1, 'buy something': 1, 'something dinner': 1, 'dinner need': 1, 'need bread': 1, 'bread milk': 1, 'milk thing': 1, 'thing get': 1, 'get picked': 1, 'picked loaf': 1, 'loaf bread': 1, 'bread two': 1, 'two point': 1, 'point five': 2, 'five gallon': 1, 'gallon milk': 1, 'milk three': 1, 'three point': 2, 'point seven': 1, 'seven nine': 1, 'nine suppose': 1, 'suppose three': 1, 'five nine': 1, 'nine price': 1, 'price tag': 1, 'tag wrong': 1, 'wrong saw': 1, 'saw pack': 1, 'pack cooky': 1, 'cooky four': 1, 'four point': 1, 'point nine': 1, 'nine nine': 1, 'nine expiration': 1, 'expiration date': 1, 'date say': 1, 'say twelvefifteen': 1, 'twelvefifteen today': 1, 'today twelvethirteen': 1, 'twelvethirteen thought': 1, 'thought hmm': 1, 'hmm maybe': 1, 'maybe take': 1, 'take risk': 1, 'risk checkout': 1, 'checkout realize': 1, 'realize forgotten': 1, 'forgotten wallet': 1, 'wallet home': 1, 'home 🤦\\u200d♂️': 1, '🤦\\u200d♂️ twenty': 1, 'twenty cash': 1, 'cash total': 1, 'total come': 1, 'come eighteen': 1, 'eighteen point': 1, 'point six': 1, 'six seven': 1, 'seven cashier': 1, 'cashier ask': 1, 'ask need': 1, 'need change': 1, 'change say': 1, 'say keep': 1, 'keep regret': 1, 'regret wouldve': 1, 'wouldve use': 1, 'use thirtythree': 1, 'thirtythree cent': 1, 'cent later': 1, 'later 😅': 1, '😅 way': 1, 'way home': 1, 'home ran': 1, 'ran old': 1, 'old friend': 1, 'friend mike': 1, 'mike say': 1, 'say head': 1, 'head park': 1, 'park threezero': 1, 'threezero pm': 1, 'pm tomorrow': 1, 'tomorrow ask': 1, 'ask want': 1, 'want meet': 1, 'meet say': 1, 'say yes': 1, 'yes forgot': 1, 'forgot ask': 1, 'ask park': 1, 'park —': 1, '— central': 1, 'central park': 1, 'park liberty': 1, 'liberty park': 1, 'park ill': 1, 'ill text': 1, 'text phone': 1, 'phone battery': 1, 'battery fifteen': 1, 'fifteen dont': 1, 'dont charger': 1, 'charger get': 1, 'get home': 1, 'home decide': 1, 'decide cook': 1, 'cook dinner': 1, 'dinner open': 1, 'open fridge': 1, 'fridge found': 1, 'found chicken': 1, 'chicken sit': 1, 'sit like': 1, 'like four': 1, 'four day': 1, 'day thought': 1, 'thought probably': 1, 'probably cook': 1, 'cook go': 1, 'go bad': 1, 'bad heat': 1, 'heat pan': 1, 'pan pour': 1, 'pour oil': 1, 'oil accidentally': 1, 'accidentally pour': 1, 'pour much': 1, 'much chicken': 1, 'chicken start': 1, 'start sizzle': 1, 'sizzle almost': 1, 'almost burn': 1, 'burn end': 1, 'end add': 1, 'add potato': 1, 'potato onion': 1, 'onion forty': 1, 'forty minute': 1, 'minute everything': 1, 'everything ready': 1, 'ready taste': 1, 'taste good': 1, 'good bit': 1, 'bit salty': 1, 'salty dinner': 1, 'dinner sat': 1, 'sat computer': 1, 'computer work': 1, 'work suppose': 1, 'suppose write': 1, 'write report': 2, 'report bos': 1, 'bos instead': 1, 'instead start': 1, 'start browsing': 1, 'browsing social': 1, 'social medium': 1, 'medium read': 1, 'read article': 1, 'article say': 1, 'say next': 1, 'next year': 1, 'year inflation': 1, 'inflation might': 1, 'might reach': 1, 'reach seven': 1, 'seven scar': 1, 'scar wage': 1, 'wage arent': 1, 'arent go': 1, 'go fast': 1, 'fast enough': 1, 'enough waste': 1, 'waste thirty': 1, 'thirty minute': 1, 'minute finally': 1, 'finally start': 1, 'start write': 1, 'report ten': 1, 'ten minute': 1, 'minute realize': 1, 'realize hadnt': 1, 'hadnt save': 1, 'save file': 1, 'file disappear': 1, 'disappear start': 1, 'start 😡': 1, '😡 overall': 1, 'overall long': 1, 'long tire': 1, 'tire day': 1, 'day bed': 1, 'bed watch': 1, 'watch two': 1, 'two episode': 1, 'episode favorite': 1, 'favorite show': 1, 'show —': 1, '— help': 1, 'help relax': 1, 'relax go': 1, 'go bed': 1, 'bed elevenfortyfive': 1, 'elevenfortyfive pm': 1, 'pm couldnt': 1, 'couldnt fall': 1, 'fall asleep': 1, 'asleep kept': 1, 'kept think': 1, 'think wake': 1, 'wake early': 1, 'early tomorrow': 1, 'tomorrow need': 1, 'need work': 1, 'work eightthirty': 1, 'eightthirty set': 1, 'set alarm': 1, 'alarm sixfortyfive': 1, 'sixfortyfive oh': 1, 'oh cant': 1, 'cant forget': 1, 'forget meeting': 1, 'meeting mike': 1, 'mike park': 1, 'park hope': 1, 'hope dont': 1, 'dont oversleep': 1}\n",
      "{'yesterday go store buy': 1, 'go store buy something': 1, 'store buy something dinner': 1, 'buy something dinner need': 1, 'something dinner need bread': 1, 'dinner need bread milk': 1, 'need bread milk thing': 1, 'bread milk thing get': 1, 'milk thing get picked': 1, 'thing get picked loaf': 1, 'get picked loaf bread': 1, 'picked loaf bread two': 1, 'loaf bread two point': 1, 'bread two point five': 1, 'two point five gallon': 1, 'point five gallon milk': 1, 'five gallon milk three': 1, 'gallon milk three point': 1, 'milk three point seven': 1, 'three point seven nine': 1, 'point seven nine suppose': 1, 'seven nine suppose three': 1, 'nine suppose three point': 1, 'suppose three point five': 1, 'three point five nine': 1, 'point five nine price': 1, 'five nine price tag': 1, 'nine price tag wrong': 1, 'price tag wrong saw': 1, 'tag wrong saw pack': 1, 'wrong saw pack cooky': 1, 'saw pack cooky four': 1, 'pack cooky four point': 1, 'cooky four point nine': 1, 'four point nine nine': 1, 'point nine nine expiration': 1, 'nine nine expiration date': 1, 'nine expiration date say': 1, 'expiration date say twelvefifteen': 1, 'date say twelvefifteen today': 1, 'say twelvefifteen today twelvethirteen': 1, 'twelvefifteen today twelvethirteen thought': 1, 'today twelvethirteen thought hmm': 1, 'twelvethirteen thought hmm maybe': 1, 'thought hmm maybe take': 1, 'hmm maybe take risk': 1, 'maybe take risk checkout': 1, 'take risk checkout realize': 1, 'risk checkout realize forgotten': 1, 'checkout realize forgotten wallet': 1, 'realize forgotten wallet home': 1, 'forgotten wallet home 🤦\\u200d♂️': 1, 'wallet home 🤦\\u200d♂️ twenty': 1, 'home 🤦\\u200d♂️ twenty cash': 1, '🤦\\u200d♂️ twenty cash total': 1, 'twenty cash total come': 1, 'cash total come eighteen': 1, 'total come eighteen point': 1, 'come eighteen point six': 1, 'eighteen point six seven': 1, 'point six seven cashier': 1, 'six seven cashier ask': 1, 'seven cashier ask need': 1, 'cashier ask need change': 1, 'ask need change say': 1, 'need change say keep': 1, 'change say keep regret': 1, 'say keep regret wouldve': 1, 'keep regret wouldve use': 1, 'regret wouldve use thirtythree': 1, 'wouldve use thirtythree cent': 1, 'use thirtythree cent later': 1, 'thirtythree cent later 😅': 1, 'cent later 😅 way': 1, 'later 😅 way home': 1, '😅 way home ran': 1, 'way home ran old': 1, 'home ran old friend': 1, 'ran old friend mike': 1, 'old friend mike say': 1, 'friend mike say head': 1, 'mike say head park': 1, 'say head park threezero': 1, 'head park threezero pm': 1, 'park threezero pm tomorrow': 1, 'threezero pm tomorrow ask': 1, 'pm tomorrow ask want': 1, 'tomorrow ask want meet': 1, 'ask want meet say': 1, 'want meet say yes': 1, 'meet say yes forgot': 1, 'say yes forgot ask': 1, 'yes forgot ask park': 1, 'forgot ask park —': 1, 'ask park — central': 1, 'park — central park': 1, '— central park liberty': 1, 'central park liberty park': 1, 'park liberty park ill': 1, 'liberty park ill text': 1, 'park ill text phone': 1, 'ill text phone battery': 1, 'text phone battery fifteen': 1, 'phone battery fifteen dont': 1, 'battery fifteen dont charger': 1, 'fifteen dont charger get': 1, 'dont charger get home': 1, 'charger get home decide': 1, 'get home decide cook': 1, 'home decide cook dinner': 1, 'decide cook dinner open': 1, 'cook dinner open fridge': 1, 'dinner open fridge found': 1, 'open fridge found chicken': 1, 'fridge found chicken sit': 1, 'found chicken sit like': 1, 'chicken sit like four': 1, 'sit like four day': 1, 'like four day thought': 1, 'four day thought probably': 1, 'day thought probably cook': 1, 'thought probably cook go': 1, 'probably cook go bad': 1, 'cook go bad heat': 1, 'go bad heat pan': 1, 'bad heat pan pour': 1, 'heat pan pour oil': 1, 'pan pour oil accidentally': 1, 'pour oil accidentally pour': 1, 'oil accidentally pour much': 1, 'accidentally pour much chicken': 1, 'pour much chicken start': 1, 'much chicken start sizzle': 1, 'chicken start sizzle almost': 1, 'start sizzle almost burn': 1, 'sizzle almost burn end': 1, 'almost burn end add': 1, 'burn end add potato': 1, 'end add potato onion': 1, 'add potato onion forty': 1, 'potato onion forty minute': 1, 'onion forty minute everything': 1, 'forty minute everything ready': 1, 'minute everything ready taste': 1, 'everything ready taste good': 1, 'ready taste good bit': 1, 'taste good bit salty': 1, 'good bit salty dinner': 1, 'bit salty dinner sat': 1, 'salty dinner sat computer': 1, 'dinner sat computer work': 1, 'sat computer work suppose': 1, 'computer work suppose write': 1, 'work suppose write report': 1, 'suppose write report bos': 1, 'write report bos instead': 1, 'report bos instead start': 1, 'bos instead start browsing': 1, 'instead start browsing social': 1, 'start browsing social medium': 1, 'browsing social medium read': 1, 'social medium read article': 1, 'medium read article say': 1, 'read article say next': 1, 'article say next year': 1, 'say next year inflation': 1, 'next year inflation might': 1, 'year inflation might reach': 1, 'inflation might reach seven': 1, 'might reach seven scar': 1, 'reach seven scar wage': 1, 'seven scar wage arent': 1, 'scar wage arent go': 1, 'wage arent go fast': 1, 'arent go fast enough': 1, 'go fast enough waste': 1, 'fast enough waste thirty': 1, 'enough waste thirty minute': 1, 'waste thirty minute finally': 1, 'thirty minute finally start': 1, 'minute finally start write': 1, 'finally start write report': 1, 'start write report ten': 1, 'write report ten minute': 1, 'report ten minute realize': 1, 'ten minute realize hadnt': 1, 'minute realize hadnt save': 1, 'realize hadnt save file': 1, 'hadnt save file disappear': 1, 'save file disappear start': 1, 'file disappear start 😡': 1, 'disappear start 😡 overall': 1, 'start 😡 overall long': 1, '😡 overall long tire': 1, 'overall long tire day': 1, 'long tire day bed': 1, 'tire day bed watch': 1, 'day bed watch two': 1, 'bed watch two episode': 1, 'watch two episode favorite': 1, 'two episode favorite show': 1, 'episode favorite show —': 1, 'favorite show — help': 1, 'show — help relax': 1, '— help relax go': 1, 'help relax go bed': 1, 'relax go bed elevenfortyfive': 1, 'go bed elevenfortyfive pm': 1, 'bed elevenfortyfive pm couldnt': 1, 'elevenfortyfive pm couldnt fall': 1, 'pm couldnt fall asleep': 1, 'couldnt fall asleep kept': 1, 'fall asleep kept think': 1, 'asleep kept think wake': 1, 'kept think wake early': 1, 'think wake early tomorrow': 1, 'wake early tomorrow need': 1, 'early tomorrow need work': 1, 'tomorrow need work eightthirty': 1, 'need work eightthirty set': 1, 'work eightthirty set alarm': 1, 'eightthirty set alarm sixfortyfive': 1, 'set alarm sixfortyfive oh': 1, 'alarm sixfortyfive oh cant': 1, 'sixfortyfive oh cant forget': 1, 'oh cant forget meeting': 1, 'cant forget meeting mike': 1, 'forget meeting mike park': 1, 'meeting mike park hope': 1, 'mike park hope dont': 1, 'park hope dont oversleep': 1}\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = BagOfWords(eng_output).create_bag()\n",
    "bigrams = NGrams(eng_output).create_ngrams(n=2)\n",
    "ngrams = NGrams(eng_output).create_ngrams(n=4)\n",
    "\n",
    "print(bag_of_words)\n",
    "print(bigrams)\n",
    "print(ngrams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
